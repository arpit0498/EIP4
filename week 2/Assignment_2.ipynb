{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RISHABHsharm/EIP4/blob/master/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "0a6ee0c0-d25e-40d3-c9a9-8cc3a96ad20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fae70679438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO1ElEQVR4nO3dfZBV9X3H8c+XZV2UhIYntyvQEAKO\nBRmhXaE1TIK1yRgnFRMzGqbJ4MTpplNIE4dp6sNMNNOZDu00Wk3z0LUSiUmwGR8iSZwYukOGZkwc\nFoI8iDyEgEJ5iOIIiDzs8u0fe3A2uOd3l3vuk3zfr5mde+/53nPP16sfz73nd8/5mbsLwPlvSL0b\nAFAbhB0IgrADQRB2IAjCDgQxtJYbu8BafJiG13KTQCjH9YZO+gkbqFYo7GZ2raT7JTVJ+i93X5J6\n/jAN12y7psgmASQ85125tbI/xptZk6SvS/qopKmS5pvZ1HJfD0B1FfnOPkvSDnff6e4nJT0qaV5l\n2gJQaUXCPk7Sy/0e78mW/R4z6zCzbjPrPqUTBTYHoIiqH4139053b3f39ma1VHtzAHIUCfteSRP6\nPR6fLQPQgIqEfY2kKWb2PjO7QNKnJK2oTFsAKq3soTd37zGzRZKeUd/Q21J331yxzgBUVKFxdnd/\nWtLTFeoFQBXxc1kgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig\n7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeC\nKDSLK9A0elSybn8wIrf20o2XJNc9PsaT9clfeT5ZP33sWLIeTaGwm9kuSUck9Urqcff2SjQFoPIq\nsWe/2t1fqcDrAKgivrMDQRQNu0v6mZmtNbOOgZ5gZh1m1m1m3ad0ouDmAJSr6Mf4Oe6+18wulrTS\nzF5099X9n+DunZI6JWmEjUofcQFQNYX27O6+N7s9KOlJSbMq0RSAyis77GY23Mzefea+pI9I2lSp\nxgBUVpGP8a2SnjSzM6/zfXf/aUW6Qs0MufyyZH37HRcm65+d/myyvnj0M+fc02D9cevfJutTbllb\ntW2/E5UddnffKemKCvYCoIoYegOCIOxAEIQdCIKwA0EQdiAITnE9D9iV03NrO25rSq778zn/kayP\nbWpJ1oeU2F/85NjI3NrOExcn1104cmuy/sgHH0zW/+nKBbk1X7Mxue75iD07EARhB4Ig7EAQhB0I\ngrADQRB2IAjCDgTBOHsDaBo7Nlnfdv+4ZP1HV30jtzapubnE1tPj6KV8+/CEZP2HN87JrZ1uSfe2\n8Mfpcfb2lt5k/c3W/NNzhyXXPD+xZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnbwB7Pz0lWd/8\noftLvEKpsfTyfbfUOPoNVyXrvVu35dZs5rSyekJ52LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCM\nszeAcdfvqtprP3b0D5P1e7ddk6y3fsmT9d6t28+5pzNemz6i7HVx7kru2c1sqZkdNLNN/ZaNMrOV\nZrY9u82fCQBAQxjMx/iHJV171rLbJXW5+xRJXdljAA2sZNjdfbWkQ2ctnidpWXZ/maQbKtwXgAor\n9zt7q7vvy+7vl9Sa90Qz65DUIUnDdFGZmwNQVOGj8e7uknKP4rh7p7u3u3t7c8GLGwIoX7lhP2Bm\nbZKU3R6sXEsAqqHcsK+QdGY+3AWSnqpMOwCqpeR3djNbLmmupDFmtkfS3ZKWSPqBmd0qabekm6rZ\n5Hnvb9Jfb6Yu/HyyPmFl/vXTh2/en1x3zO78880lKX1l9mKOtVoVXx1nKxl2d5+fU0r/GgNAQ+Hn\nskAQhB0IgrADQRB2IAjCDgTBKa4NoHfHb5P1ybel6yk9Za9ZfaeuPFLvFkJhzw4EQdiBIAg7EARh\nB4Ig7EAQhB0IgrADQTDOHtxLX05PudxzUfpS0ip1lmpi9U9M+WWJldMW7ZmbrF/403W5tRL/VOcl\n9uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7O8ATSPSUxsfnzUlt9Z8x4Hkuhsu+1pZPb31+taU\nrJ/y8i9GverN9HRhezr+KFn3ni1lb/t8xJ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0GrCU9\nJfPJD01P1m/7xiPJ+tUXduXWDvSeSK676s2RyfqXt81L1pdPezhZv2Ro+p89ZdiQU8n6zpvek6xP\n2jost3b6+PGyenonK7lnN7OlZnbQzDb1W3aPme01s/XZ33XVbRNAUYP5GP+wpGsHWH6fu8/I/p6u\nbFsAKq1k2N19taRDNegFQBUVOUC3yMw2ZB/zc7/4mVmHmXWbWfcppb8/AqiecsP+TUnvlzRD0j5J\nX817ort3unu7u7c3q/yDNQCKKSvs7n7A3Xvd/bSkByXNqmxbACqtrLCbWVu/hx+XtCnvuQAaQ8lx\ndjNbLmmupDFmtkfS3ZLmmtkM9V1+e5ekz1Wxx4Y3ZFj+eK4kvXrzzGT9f//5gULbn7b887m18avS\n55O3/GRNsj667WiyvvyZP03WF48ufz8wuyU9zr7hlvT79ucv/31urfU7zyfXPX3sWLL+TlQy7O4+\nf4DFD1WhFwBVxM9lgSAIOxAEYQeCIOxAEIQdCMLcazd57Qgb5bPtmpptr5JSp6luve+K5Lovzvt6\noW3P23pDsj5kfv4QVe+Bg8l1h04Yn6xfseKlZP0rF/86WX/9dP6ppLMfX5xct+2ydO9d0/87WU+5\necfHkvVXHpiYrA97NT0sWErTz/Onky7iOe/SYT804ETa7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2\nIAguJZ2xoem3Yuu/54+lv3h9ehx9T0/6clzX/+eXkvWJS3+TrPckxtJP/WX6FNTL/yU9Tn73xWuT\n9W8ffm+y/shdf5Vbm/zEr5LrNo0ZnazP/XD+qb2S9MbNr+fWnpz5YHLd8Q8Uu6rSj99I99556aRC\nr18O9uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATns2f23HFVsr5u0f25tf8rMY5+45J/SNbbfvjb\nZP3Q1ROTdf/0K7m1xy5/OLnu2Kb0ePK0R9Nj2Zd25m9bknq37kjW6+Xg36X/fbd+cnexDSxOTyft\nv95c7PVzcD47AMIOREHYgSAIOxAEYQeCIOxAEIQdCIJx9sxdO9cn66npgw/1psfZv/Xa7GR93AWv\nJesLRhQc802Y9v38aY0lafId6Smdvaenku2goELj7GY2wcxWmdkLZrbZzL6QLR9lZivNbHt2O7LS\njQOonMF8jO+RtNjdp0r6M0kLzWyqpNsldbn7FEld2WMADapk2N19n7uvy+4fkbRF0jhJ8yQty562\nTFJ6jiIAdXVO16Azs4mSZkp6TlKru+/LSvslteas0yGpQ5KG6aJy+wRQ0KCPxpvZuyQ9LumL7n64\nf837jvINeKTP3Tvdvd3d25tV7CJ+AMo3qLCbWbP6gv49d38iW3zAzNqyepuk9JSbAOqq5Md4MzNJ\nD0na4u739iutkLRA0pLs9qmqdFgjq49elqzPbtmYWxtV4jTRO8ekh/VK+diLn0jWX/pl/rTLkx7L\nv5yyJE3enL5UNENr54/BfGf/gKTPSNpoZmf+q71TfSH/gZndKmm3pJuq0yKASigZdnf/haQBB+kl\nNeYvZAC8DT+XBYIg7EAQhB0IgrADQRB2IAimbM48e/Ulyfrsv/6L3NrrV5xMrjv0d83J+qXf2pte\nf3/690oTj7+cWzudXBORsGcHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAYZ8/0vnooWW994Nn8WsFt\nc8Y4aoE9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjC\nDgRRMuxmNsHMVpnZC2a22cy+kC2/x8z2mtn67O+66rcLoFyDuXhFj6TF7r7OzN4taa2Zrcxq97n7\nv1WvPQCVMpj52fdJ2pfdP2JmWySNq3ZjACrrnL6zm9lESTMlPZctWmRmG8xsqZmNzFmnw8y6zaz7\nlE4UahZA+QYddjN7l6THJX3R3Q9L+qak90uaob49/1cHWs/dO9293d3bm9VSgZYBlGNQYTezZvUF\n/Xvu/oQkufsBd+9199OSHpQ0q3ptAihqMEfjTdJDkra4+739lrf1e9rHJW2qfHsAKmUwR+M/IOkz\nkjaa2fps2Z2S5pvZDEkuaZekz1WlQwAVMZij8b+QZAOUnq58OwCqhV/QAUEQdiAIwg4EQdiBIAg7\nEARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3r93GzH4naXe/RWMkvVKzBs5No/bW\nqH1J9FauSvb2XncfO1ChpmF/28bNut29vW4NJDRqb43al0Rv5apVb3yMB4Ig7EAQ9Q57Z523n9Ko\nvTVqXxK9lasmvdX1OzuA2qn3nh1AjRB2IIi6hN3MrjWzrWa2w8xur0cPecxsl5ltzKah7q5zL0vN\n7KCZbeq3bJSZrTSz7dntgHPs1am3hpjGOzHNeF3fu3pPf17z7+xm1iRpm6QPS9ojaY2k+e7+Qk0b\nyWFmuyS1u3vdf4BhZh+UdFTSd9z98mzZv0o65O5Lsv9RjnT3f2yQ3u6RdLTe03hnsxW19Z9mXNIN\nkm5RHd+7RF83qQbvWz327LMk7XD3ne5+UtKjkubVoY+G5+6rJR06a/E8Scuy+8vU9x9LzeX01hDc\nfZ+7r8vuH5F0Zprxur53ib5qoh5hHyfp5X6P96ix5nt3ST8zs7Vm1lHvZgbQ6u77svv7JbXWs5kB\nlJzGu5bOmma8Yd67cqY/L4oDdG83x93/RNJHJS3MPq42JO/7DtZIY6eDmsa7VgaYZvwt9Xzvyp3+\nvKh6hH2vpAn9Ho/PljUEd9+b3R6U9KQabyrqA2dm0M1uD9a5n7c00jTeA00zrgZ47+o5/Xk9wr5G\n0hQze5+ZXSDpU5JW1KGPtzGz4dmBE5nZcEkfUeNNRb1C0oLs/gJJT9Wxl9/TKNN4500zrjq/d3Wf\n/tzda/4n6Tr1HZH/jaS76tFDTl+TJD2f/W2ud2+SlqvvY90p9R3buFXSaEldkrZL+h9Joxqot0ck\nbZS0QX3BaqtTb3PU9xF9g6T12d919X7vEn3V5H3j57JAEBygA4Ig7EAQhB0IgrADQRB2IAjCDgRB\n2IEg/h8CIWRCsmbzCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "0d22bc4a-d4d0-471b-8b4d-8cf232cdce4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "25b87c20-14e4-4115-819b-8e1ce7dbf3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, bias= False, activation='relu', input_shape=(28,28,1))) # 26\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, bias= False, activation='relu')) # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(10, 1, bias= False, activation='relu')) # 11\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias= False, activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, bias= False,activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(10, 1, bias= False,activation='relu')) #7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., use_bias=False)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, 1, activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, 1, activation=\"relu\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_369 (Conv2D)          (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_267 (Bat (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_370 (Conv2D)          (None, 24, 24, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_268 (Bat (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_120 (Dropout)        (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_371 (Conv2D)          (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_269 (Bat (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_372 (Conv2D)          (None, 11, 11, 10)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_270 (Bat (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_121 (Dropout)        (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_373 (Conv2D)          (None, 9, 9, 16)          1440      \n",
            "_________________________________________________________________\n",
            "batch_normalization_271 (Bat (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_374 (Conv2D)          (None, 7, 7, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_272 (Bat (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_122 (Dropout)        (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_375 (Conv2D)          (None, 7, 7, 10)          160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_273 (Bat (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_376 (Conv2D)          (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_47 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,142\n",
            "Trainable params: 13,942\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "5eac4e46-8ef4-4b52-91d0-d202299f9e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.1741 - acc: 0.9436 - val_loss: 0.0487 - val_acc: 0.9842\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0557 - acc: 0.9828 - val_loss: 0.0473 - val_acc: 0.9853\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0436 - acc: 0.9869 - val_loss: 0.0323 - val_acc: 0.9894\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0357 - acc: 0.9887 - val_loss: 0.0303 - val_acc: 0.9906\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0318 - acc: 0.9899 - val_loss: 0.0245 - val_acc: 0.9921\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0284 - acc: 0.9907 - val_loss: 0.0266 - val_acc: 0.9932\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0221 - val_acc: 0.9934\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0238 - acc: 0.9925 - val_loss: 0.0222 - val_acc: 0.9922\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0220 - acc: 0.9928 - val_loss: 0.0230 - val_acc: 0.9928\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0215 - acc: 0.9928 - val_loss: 0.0230 - val_acc: 0.9928\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.0220 - val_acc: 0.9930\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9942\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0217 - val_acc: 0.9932\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0200 - val_acc: 0.9939\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0198 - val_acc: 0.9938\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0158 - acc: 0.9947 - val_loss: 0.0205 - val_acc: 0.9936\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0138 - acc: 0.9955 - val_loss: 0.0208 - val_acc: 0.9938\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0213 - val_acc: 0.9940\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0131 - acc: 0.9953 - val_loss: 0.0215 - val_acc: 0.9936\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0193 - val_acc: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae466872e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "8ec344a3-2be0-4a8c-aa19-11fbd3a12af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01932154694770652, 0.9941]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}